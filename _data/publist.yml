- title: "Optimization Strategies for BERT-based Named Entity Recognition"
  image: BRACIS_ModelSoup_2023.png
  description: We evaluates the state-of-the-art NER models BiLSTM+CRF and BERT+Fine-Tunning trained on Portuguese corpora through finetuning in the legal and legislative domains.
  authors: M. L. B. MONTEIRO, C. ZANCHETTIN
  link:
    url: 
    display:   Brazilian Conference on Intelligent Systems, 2023
  highlight: 1
  news2:
  
- title: "On the Assessment of Deep Learning Models for Named Entity Recognition of Brazilian Legal Documents"
  image: EAPIA_2023.png
  description: We evaluates the state-of-the-art NER models BiLSTM+CRF and BERT+Fine-Tunning trained on Portuguese corpora through finetuning in the legal and legislative domains.
  authors: H. O. ALBUQUERQUE, E. SOUZA, A. L. I OLIVEIRA, D. L. MACEDO, D. VITORIO, C. ZANCHETTIN, N. F. F. SILVA, A. C. P. L. F CARVALHO
  link:
    url: 
    display:   Portuguese Conference on Artificial Intelligence, 2023
  highlight: 1
  news2:
  
- title: "Exploring the Impact of Synthetic Data on Human Activity Recognition Tasks"
  image: INNS-DL_GAN_2023.png
  description: We analyze the performance of three Generative Adversarial Networks (GANs) and a Diffuse model, considering fidelity, diversity, and generalization metrics. In addition, we assess the relationship between the addition of synthetic samples to the training data and the impact of imbalanced classes on the generative model in the production of synthetic samples. We also introduce a novel GAN designed to generate synthetic samples of time series data from wearable devices.
  authors: M. D. SOUZA, C. R. SILVA JUNIOR, A. L. SANTOS, J. QUINTINO, F. Q. B. SILVA, C. ZANCHETTIN
  link:
    url: 
    display:   INNS Deep Learning Innovations and Applications, 2023
  highlight: 1
  news2:
  
- title: "Learning What, Where and Which to Transfer"
  image: IJCNN_LWWWT_2023.png
  description: We propose add pixel-level information in addition to layers and channels information from the source network to guide the target network training. The idea is to use meta-networks to enhance the knowledge transfer process bridging the source and target networks, deciding which pairs of information should be matched for optimal knowledge transfer. 
  authors: L. L. NOGUEIRA, F. M. DE PAULA NETO, D. L. MACEDO, A. L. I. OLIVEIRA, C. ZANCHETTIN
  link:
    url: 
    display:   International Joint Conference on Neural Networks, 2023
  highlight: 1
  news2:
  
- title: "Self-Calibrated U-Net for Document Segmentation"
  image: IJCNN_Self-Calibrated-U-Net_2023.png
  description: We propose a new fully convolutional network architecture based on U-Net for segmentation associated with self-calibrated convolution. 
  authors: I. R. RODRIGUES, L. G. F., SILVA, D. L. MACEDO, C. ZANCHETTIN, P. T. ENDO, D. SADOK
  link:
    url: 
    display:   International Joint Conference on Neural Networks, 2023
  highlight: 1
  news2:
  
- title: "Improving Small Object Detection with DETRAug"
  image: IJCNN_AUGMIX_2023.png
  description: We present a novel method for enhancing the robustness of image detection models using AUGMIX. Our approach involves applying various augmentations to the input images in a stochastic manner, resulting in a single output image after all transformations have been applied.
  authors: E. CUNHA, D. L. MACEDO, C. ZANCHETTIN
  link:
    url: 
    display:   International Joint Conference on Neural Networks, 2023
  highlight: 1
  news2:
  
- title: "Detecting Malicious HTTP Requests Without Log Parser Using RequestBERT-BiLSTM"
  image: BRACIS_requestBERT_2022.png
  description: We present the RequestBERT-BiLSTM, a new model to detect possible HTTP request attacks without using Log Parser.
  authors: RAMOS JUNIOR, L. S., D. L. MACEDO, A. L. I. OLIVEIRA, C. ZANCHETTIN
  link:
    url: https://doi.org/10.1007/978-3-031-21689-3_24
    display:   Brazilian Conference on Intelligent Systems, 2022
  highlight: 1
  news2:
  
- title: "Training Aware Sigmoidal Optimization"
  image: BRACIS_TASO_2022.png
  description: We proposed the Training Aware Sigmoidal Optimizer (TASO), consisting of a two-phase automated learning rate schedule. The first phase uses a high learning rate to fast traverse the numerous saddle point, while the second phase uses a low learning rate to approach the center of the local minimum previously found slowly.
  authors: D. L. MACEDO, P. H. D. LEUCHTENBERG, T. B. LUDERMIR, C. ZANCHETTIN
  link:
    url: https://doi.org/10.1007/978-3-031-21689-3_10
    display:   Brazilian Conference on Intelligent Systems, 2022
  highlight: 1
  news2:
  
- title: "LogBERT-BiLSTM: Detecting Malicious Web Requests"
  image: ICANN_LogBERT_2022.png
  description: We propose a new approach to detect possible attacks on HTTP requests based on machine learning. The new model LogBERT-BiLSTM uses BERT and Bidirectional LSTMs to detect anomalies in data.
  authors: RAMOS JUNIOR, L. S., MACEDO, A. L. I. OLIVEIRA, C. ZANCHETTIN
  link:
    url: https://doi.org/10.1007/978-3-031-15934-3_58
    display:   International Conference on Artificial Neural Networks, 2022
  highlight: 1
  news2:

- title: "An Adapted GRASP Approach for Hyperparameter Search on Deep Networks Applied to Tabular Data"
  image: IJCNN_Grasp_2022.png
  description: We propose a simple and effective approach based on the Greedy Randomized Adaptive Search Procedure (GRASP) algorithm that we adapt to optimize deep neural networks models.
  authors: A. A. SILVA, A. S. XAVIER, D. L. MACEDO, A. L. I. OLIVEIRA, C. ZANCHETTIN
  link:
    url: https://doi.org/10.1109/IJCNN55064.2022.9892288
    display:   International Joint Conference on Neural Networks, 2022
  highlight: 1
  news2:
  
- title: "Unsupervised Multi-view Multi-person 3D Pose Estimation Using Reprojection Error"
  image: ICANN_3DPose_2022.png
  description: We propose an unsupervised approach to estimating 3D human poses requiring only an off-the-shelf 2D pose estimation method and the intrinsic and extrinsic camera parameters. 
  authors: D. W. F. SILVA; J. P. S. M. LIMA, D. L., MACEDO, C. ZANCHETTIN; D. G. F., THOMAS; H. UCHIYAMA; V. TEICHRIEB
  link:
    url: https://doi.org/10.1007/978-3-031-15934-3_40
    display:   International Conference on Artificial Neural Networks, 2022
  highlight: 1
  news2:

- title: "Multi-human Fall Detection and Localization in Videos"
  image: ImageUnd_2022.jpg
  description: We propose two options for the overall end-to-end trainable architectures. The first option is created using the YOLOK tracking stage with a classification stage based on the 3DCNN classification block. The second option is created by combining the YOLOK tracking stage with a classification stage.
  authors: M. E. N. Gomes, D. Macêdo, C. Zanchettin, P. S. G. Mattos-Neto and A. L. I. Oliveira
  link:
    url: https://doi.org/10.1016/j.cviu.2022.103442
    display:   Computer Vision and Image Understanding, 2022
  highlight: 1
  news2:

- title: "PictoBERT: Transformers for next pictogram prediction"
  image: PictoBERT_ESWA_2022.jpg
  description: We present PictoBERT, an adaptation of BERT for the next pictogram prediction task. We changed the BERT’s input embeddings to allow word-sense usage instead of words, considering that a word-sense represents a pictogram better than a simple word.
  authors: J. A. Pereiraa, D. Macêdo, C. Zanchettin, A. L. I. Oliveira and R. N. Fidalgo
  link:
    url: https://doi.org/10.1016/j.eswa.2022.117231
    display:   Expert Systems with Applications, 2022
  highlight: 1
  news2:
  
- title: "Convolution Optimization in Fire Classification"
  image: IEEEACEESS_FIRE_2022.png
  description: We propose the KutralNext architecture, an efficient model for single- and multi-label fire and smoke recognition tasks.
  authors: A. Ayala, B. Fernandes, F. Cruz, D. Macêdo and C. Zanchettin
  link:
    url: https://doi.org/10.1109/ACCESS.2022.3151660
    display:   IEEE Access, 2022
  highlight: 1
  news2:
  
- title: "Identification of Microorganism Colony Odor Signature using InceptionTime"
  image: SMC_Nose_2021.png
  description: We propose signature identification of these colony odors from microorganisms using InceptionTime. The InceptionTime model is a set of models of the deep convolutional neural network, inspired by the Inception-v4 architecture.
  authors: P. J. M. Vasconcelos, D. Macêdo, L. M. Almeida, R. L. G. Neto, C. A. Benevides, C. Zanchettin, A. L. I. Oliveira
  link:
    url: https://doi.org/10.1109/SMC52423.2021.9658669
    display:  IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2021
  highlight: 1
  news2:
  
- title: "Multi-class Mobile Money Service Financial Fraud Detection by Integrating Supervised Learning with Adversarial Autoencoders"
  image: IJCNN_Fraud_2021.png
  description: We propose an integration of adversarial autoencoders and machine learning methods to perform an objective classification among three transaction types, regular, local and global anomaly. The integration consists of using the autoencoder's generated latent vectors as features for the supervised learning algorithms. 
  authors: J. C. S. Silva, D. Macêdo, C. Zanchettin, A. L. I. Oliveira, A. T. Almeida-Filho
  link:
    url: https://doi.org/10.1109/IJCNN52387.2021.9533313
    display:  International Joint Conference on Neural Networks, 2021
  highlight: 1
  news2:

- title: "Intrusion Detection for Cyber-Physical Systems using Generative Adversarial Networks in Fog Environment"
  image: IEEE_IoT_2020.png
  description: We propose FID-GAN, a novel fog-based, unsupervised intrusion detection system (IDS) for CPSs using GANs. The IDS is proposed for a fog architecture, which brings computation resources closer to the end nodes and thus contributes to meeting low-latency requirements.
  authors: P. F. de Araujo-Filho, G. Kaddoum, D. R. Campelo, A. G. Santos, D. Macêdo and C. Zanchettin
  link:
    url: https://doi.org/10.1109/JIOT.2020.3024800
    display:  IEEE Internet of Things Journal, 2020
  highlight: 1
  news2:

- title: "KutralNet: A Portable Deep Learning Model for Fire Recognition"
  image: IJCNN_KutralNet_2020.png
  description: We propose a new deep learning architecture that requires fewer floating-point operations (flops) for fire recognition. Additionally, we propose a portable approach for fire recognition and the use of modern techniques such as inverted residual block, convolutions like depth-wise, and octave, to reduce the model's computational cost.
  authors: A. Ayala, B. J. T. Fernandes, F. Cruz, D. Macêdo, A. L. I. Oliveira, C. Zanchettin
  link:
    url: http://dx.doi.org/10.1109/IJCNN48605.2020.9207202
    display:  International Joint Conference on Neural Networks, 2020
  highlight: 1
  news2:

- title: "A Fast Fully Octave Convolutional Neural Network for Document Image Segmentation"
  image: IJCNN_Segmentation_2020.png
  description: We investigated a method based on U-Net to detect the document edges and text regions in ID images. Besides the promising results on image segmentation, the U-Net based approach is computationally expensive for a real application, since the image segmentation is a customer device task. We propose a model optimization based on Octave Convolutions to qualify the method to situations where storage, processing, and time resources are limited, such as in mobile and robotic applications.
  authors: R. B. Neves Junior, L. F. Vercosa, D. Macêdo, A. L. I. Oliveira, C. Zanchettin 
  link:
    url: http://dx.doi.org/10.1109/IJCNN48605.2020.9206711
    display:  International Joint Conference on Neural Networks, 2020
  highlight: 1
  news2:

- title: "AM-MobileNet1D: A Portable Model for Speaker Recognition"
  image: IJCNN_AM-MobileNet1D_2020.png
  description: We propose a portable model called Additive Margin MobileNet1D (AM-MobileNet1D) to Speaker Identification on mobile devices. We evaluated the proposed approach on TIMIT and MIT datasets obtaining equivalent or better performances concerning the baseline methods. Additionally, the proposed model takes only 11.6 megabytes on disk storage against 91.2 from SincNet and AM-SincNet architectures, making the model seven times faster, with eight times fewer parameters.
  authors: J. A. C. Nunes, D. Macêdo, C. Zanchettin
  link:
    url: http://dx.doi.org/10.1109/IJCNN48605.2020.9207519
    display:  International Joint Conference on Neural Networks, 2020
  highlight: 1
  news2:

- title: "Distantly-Supervised Neural Relation Extraction with Side Information using BERT"
  image: IJCNN_BERT-SIDE_2020.png
  description: We propose a related approach to RESIDE also using additional side information, but simplifying the sentence encoding with BERT embeddings. Through experiments, we show the effectiveness of the proposed method in Google Distant Supervision and Riedel datasets concerning the BGWA and RESIDE baseline methods. Although Area Under the Curve is decreased because of unbalanced datasets, P@N results have shown that the use of BERT as sentence encoding allows superior performance to baseline methods.
  authors: J. Moreira, C. Oliveira, D. Macêdo, C. Zanchettin, L. A. Barbosa
  link:
    url: http://dx.doi.org/10.1109/IJCNN48605.2020.9206648
    display:  International Joint Conference on Neural Networks, 2020
  highlight: 1
  news2:

- title: "Squeezed Deep 6DoF Object Detection using Knowledge Distillation"
  image: IJCNN_6DoF_2020.png
  description: We propose an approach to reduce the complexity of 6DoF detection networks while maintaining accuracy. We used Knowledge Distillation to teach portables Convolutional Neural Networks (CNN) to learn from a real-time 6DoF detection CNN. The proposed method allows real-time applications using only RGB images while decreasing the hardware requirements. We used the LINEMOD dataset to evaluate the proposed method, and the experimental results show that the proposed method reduces the memory requirement by almost 99\% in comparison to the original architecture with the cost of reducing half the accuracy in one of the metrics. 
  authors: H. Felix, W. Rodrigues, D. Macêdo, F. Simões, A. L. I. Oliveira; V. Teichrieb, C. Zanchettin
  link:
    url: http://dx.doi.org/10.1109/IJCNN48605.2020.9207459
    display:  International Joint Conference on Neural Networks, 2020
  highlight: 1
  news2:

- title: "Enhancing batch normalized convolutional networks using displaced rectifier linear units: A systematic comparative study"
  image: ESWA_DReLU_2019.png
  description: We propose the activation function Displaced Rectifier Linear Unit (DReLU) by conjecturing that extending the identity function of ReLU to the third quadrant enhances compatibility with batch normalization. Moreover, we used statistical tests to compare the impact of using distinct activation functions (ReLU, LReLU, PReLU, ELU, and DReLU) on the learning speed and test accuracy performance of standardized VGG and Residual Networks state-of-the-art models.  
  authors: D. Macêdo, C. Zanchettin, A. L.I. Oliveira, T. B. Ludermir
  link:
    url: https://doi.org/10.1016/j.eswa.2019.01.066
    display:  Expert Systems with Applications, 2019
  highlight: 1
  news2:

- title: "On the Influence of the Color Model for Image Boundary Detection Algorithms based on Convolutional Neural Networks"
  image: IJCNN_Color_2019.png
  description: We provide a qualitative analysis of boundary detection algorithms based on CNN but considering images in different color models. We have used the color models RGB, Lab, Luv, dRdGdB, YO1O2 and HSV for this analysis. The Holistically-Nested Edge Detection (HED) and Convolutional Encoder Decoder Network (CEDN) are the CNN's chosen due to their high performance. 
  authors: T. J. Dos Santos, C. A. B. Mello, C. Zanchettin, T. V. M. De Souza
  link:
    url: https://doi.org/10.1109/IJCNN.2019.8851701
    display:  International Joint Conference on Neural Networks, 2019
  highlight: 1
  news2:

- title: "Towards Optimizing Convolutional Neural Networks for Robotic Surgery Skill Evaluation"
  image: IJCNN_Robotic_2019.png
  description: We propose a novel CNN architecture for automated robot-assisted skill assessment. We explore the use of the SELU activation function and a global mixed pooling approach based on the average and max-pooling layers. Finally, we examine two types of convolutional layers, real-value and quaternion-valued. The results suggest that our model presents a higher average accuracy across the three surgical subtasks of the JIGSAWS dataset. 
  authors: D. Castro, D. Pereira, C. Zanchettin, D. Macêdo, B. L. D. Bezerra
  link:
    url: https://doi.org/10.1109/IJCNN.2019.8852341
    display:  International Joint Conference on Neural Networks, 2019
  highlight: 1
  news2:
  
- title: "Additive Margin SincNet for Speaker Recognition"
  image: IJCNN_AM-SincNet_2019.png
  description: The Softmax loss function is a widely used function in deep learning methods, but it is not the best choice for all kind of problems. For distance-based problems, one new Softmax based loss function called Additive Margin Softmax (AM-Softmax) is proving to be a better choice than the traditional Softmax. The AM-Softmax introduces a margin of separation between the classes that forces the samples from the same class to be closer to each other and also maximizes the distance between classes. In this paper, we propose a new approach for speaker recognition systems called AM-SincNet, which is based on the SincNet but uses an improved AM-Softmax layer.
  authors: J. A. C. Nunes, D. Macêdo, C. Zanchettin
  link:
    url: https://doi.org/10.1109/IJCNN.2019.8852112
    display:  International Joint Conference on Neural Networks, 2019
  highlight: 1
  news2:
  
- title: "Improving Universal Language Model Fine-Tuning using Attention Mechanism"
  image: IJCNN_ULMFiT_2019.png
  description: The Universal Language Model Fine-Tuning (ULMFiT) is a recent approach which proposes to train a language model and transfer its knowledge to a final classifier. During the classification step, ULMFiT uses a max and average pooling layer to select the useful information of an embedding sequence. We propose to replace max and average pooling layers with a soft attention mechanism. The goal is to learn the most important information of the embedding sequence rather than assuming that they are max and average values.
  authors: F. A. O. SANTOS, K. L. Ponce-Guevara, D. Macêdo, C. Zanchettin
  link:
    url: https://doi.org/10.1109/IJCNN.2019.8852398
    display:  International Joint Conference on Neural Networks, 2019
  highlight: 1
  news2:

- title: "Heartbeat Anomaly Detection using Adversarial Oversampling"
  image: IJCNN_Heartbeat_2019.png
  description:  We propose a two-dimensional Convolutional Neural Network for classification after using a InfoGAN architecture for generating synthetic images to unbalanced classes. We call this proposal Adversarial Oversampling and compare it with the classical oversampling methods as SMOTE, ADASYN, and Random Oversampling. The results show that the proposed approach improves the classifier performance for the minority classes without harming the performance in the balanced classes.
  authors: J. L. P. LIMA, D. Macêdo, C. Zanchettin
  link:
    url: https://doi.org/10.1109/IJCNN.2019.8852242
    display:  International Joint Conference on Neural Networks, 2019
  highlight: 1
  news2:
  
- title: "Otimização do Consumo de Energia em Redes Ad Hoc Aloha Empregando Deep Learning"
  image: WPerformance_2019.png
  description:  O presente artigo propõe uma nova abordagem baseada em aprendizagem de máquina que considera a entrada e a saı́da de um algoritmo de controle de consumo de energia em redes ad hoc slotted Aloha de múltiplas varáveis. Resultados mostram que a rede neural proposta obteve melhor desempenho em relação ao tempo de processamento e custo computacional quando comparado aos algoritmos de controle energético de busca gulosa utilizados atualmente.
  authors: P. F. C. Barbosa, D. Macêdo, B. A. Da Silva, R. M. De Moraes, C. Zanchettin
  link:
    url: https://doi.org/10.5753/wperformance.2019.6462
    display:  WPerformance, 2019
  highlight: 1
  news2:

- title: "Hierarchical Attentional Hybrid Neural Networks for Document Classification"
  image: ICANN_Attentional_2019.png
  description: We propose a new approach based on a combination of convolutional neural networks, gated recurrent units, and attention mechanisms for document classification tasks. We use of convolution layers varying window sizes to extract more meaningful, generalizable and abstract features by the hierarchical representation. 
  authors: J. Abreu, L. Fred, D. Macêdo, C. Zanchettin
  link:
    url: https://doi.org/10.1007/978-3-030-30493-5_39
    display:  International Conference on Artificial Neural Networks, 2019
  highlight: 1
  news2:
  
- title: "Squeezed Very Deep Convolutional Neural Networks for Text Classification"
  image: ICANN_Squeezed_2019.png
  description: We propose to modify the structure of the Very Deep Convolutional Neural Networks (VDCNN) model to reduce its storage size while keeping the model performance. In this paper, we evaluate the impact of Temporal Depthwise Separable Convolutions and Global Average Pooling in the network parameters, storage size, dedicated hardware dependence, and accuracy. The proposed squeezed model (SVDCNN) is between 10x and 20x smaller than the original version, depending on the network depth, maintaining a maximum disk size of 6MB. 
  authors: A. B. Duque, L. L. Santos, D. Macêdo, C. Zanchettin
  link:
    url: https://doi.org/10.1007/978-3-030-30487-4_16
    display:  International Conference on Artificial Neural Networks, 2019
  highlight: 1
  news2:
  
- title: "Spatial-Temporal Graph Convolutional Networks for Sign Language Recognition"
  image: ICANN_Spatial_2019.png
  description: We propose a new approach of Spatial-Temporal Graph Convolutional Network to sign language recognition based on the human skeletal movements. The method uses graphs to capture the signs dynamics in two dimensions, spatial and temporal, considering the complex aspects of the language. Additionally, we present a new dataset of human skeletons for sign language based on ASLLVD to contribute to future related studies. 
  authors: C. C. de Amorim, D. Macêdo, C. Zanchettin
  link:
    url: https://10.1007/978-3-030-30493-5_59
    display:  International Conference on Artificial Neural Networks, 2019
  highlight: 1
  news2:

- title: "Reducing SqueezeNet Storage Size with Depthwise Separable Convolutions"
  image: IJNN_SqueezeNet_2018.png
  description: We investigate the effects of storage space reduction in SqueezeNet as it relates to inference time when processing single test samples. In order to reduce the storage space, we suggest adjusting SqueezeNet's Fire Modules to include Depthwise Separable Convolutions (DSC). The resulting network, referred to as SqueezeNet-DSC, is compared to different convolutional neural networks such as MobileNet, AlexNet, VGG19, and the original SqueezeNet itself.
  authors: A. G. Santos, C. O. De Souza, C. Zanchettin, D. Macêdo, A. L. I Oliveira, T. B. Ludermir
  link:
    url: https://doi.org/10.1109/IJCNN.2018.8489442
    display:  International Joint Conference on Neural Networks, 2018
  highlight: 1
  news2:

- title: "SegNetRes-CRF: A Deep Convolutional Encoder-Decoder Architecture for Semantic Image Segmentation"
  image: IJNN_SegNetRes-CRF_2018.png
  description:  We propose some modifications in the SegNet-Basic architecture by using a post-processing segmentation layer (using Conditional Random Fields) and by transferring high resolution features combined to the decoder network. The proposed method was evaluated in the dataset CamVid. Moreover, it was compared with important variants of SegNet and showed to be able to improve the overall accuracy of SegNet-Basic by up to 17.5%.
  authors: L. A. De Oliveira Junior; H. R. Medeiros, D. Macêdo, C. Zanchettin, A. L. I. Oliveira, T. B. Ludermir
  link:
    url: https://doi.org/10.1109/IJCNN.2018.8489376
    display:  International Joint Conference on Neural Networks, 2018
  highlight: 1
  news2:
  
- title: "The Impact of Dataset Complexity on Transfer Learning over Convolutional Neural Networks"
  image: ICANN_Impact_2017.png
  description: We performed a statistical analysis through several experiments in which the convolutional neural networks (LeNet-5, AlexNet, VGG-11 and VGG-16) were trained and transferred to different target tasks layer by layer. We show that when working with complex low-quality images and small datasets, fine-tuning the transferred features learned from a low complexity source dataset gives the best results.
  authors: M. D. S. Wanderley, L. A. Bueno, C. Zanchettin, A. L. I. Oliveira
  link:
    url: https://10.1007/978-3-319-68612-748
    display:  International Conference on Neural Networks, 2017
  highlight: 1
  news2:
  